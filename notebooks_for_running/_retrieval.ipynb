{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Retrieval\n",
    "\n",
    "This notebook contains the code for the retrival pipeline."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 64,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import plotly.express as px\n",
    "from tqdm import tqdm\n",
    "import time\n",
    "import warnings\n",
    "import re\n",
    "import faiss\n",
    "\n",
    "from sklearn.metrics import precision_score, recall_score, f1_score\n",
    "from sklearn.metrics.pairwise import cosine_similarity\n",
    "from sentence_transformers import SentenceTransformer\n",
    "from sklearn.cluster import MiniBatchKMeans, KMeans\n",
    "from river import cluster\n",
    "\n",
    "from OnlineKMeans import OnlineKMeans\n",
    "\n",
    "warnings.filterwarnings(\"ignore\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Classes and functions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 65,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Encoder model\n",
    "# model = SentenceTransformer(\"all-MiniLM-L6-v2\")\n",
    "model = SentenceTransformer(\"Snowflake/snowflake-arctic-embed-l-v2.0\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 66,
   "metadata": {},
   "outputs": [],
   "source": [
    "def compute_cluster_centroids(chunk_embeddings, cluster_labels):\n",
    "    \"\"\"\n",
    "    Compute centroids once for all clusters.\n",
    "    Returns:\n",
    "        centroid_matrix: np.ndarray of shape (n_clusters, embedding_dim)\n",
    "        centroid_ids: list of cluster IDs\n",
    "    \"\"\"\n",
    "    unique_clusters = np.unique(cluster_labels)\n",
    "    cluster_centroids = {\n",
    "        cid: chunk_embeddings[cluster_labels == cid].mean(axis=0)\n",
    "        for cid in unique_clusters\n",
    "    }\n",
    "    centroid_matrix = np.vstack(list(cluster_centroids.values()))\n",
    "    centroid_ids = list(cluster_centroids.keys())\n",
    "    return centroid_matrix, centroid_ids\n",
    "\n",
    "\n",
    "def retrieve_top_chunks_by_cluster(\n",
    "    query_embedding,\n",
    "    chunk_embeddings,\n",
    "    df_chunks,\n",
    "    cluster_labels,\n",
    "    centroid_matrix,\n",
    "    centroid_ids,\n",
    "    top_n_clusters=2,\n",
    "    top_k_total=5\n",
    "):\n",
    "    # --- Use precomputed centroids ---\n",
    "    cluster_sims = cosine_similarity([query_embedding], centroid_matrix)[0]\n",
    "    top_n_idx = cluster_sims.argsort()[::-1][:top_n_clusters]\n",
    "    selected_clusters = [centroid_ids[i] for i in top_n_idx]\n",
    "\n",
    "    # Collect all chunks from selected clusters\n",
    "    mask = np.isin(cluster_labels, selected_clusters)\n",
    "    selected_chunk_embeddings = chunk_embeddings[mask]\n",
    "    selected_df = df_chunks[mask].reset_index(drop=True)\n",
    "\n",
    "    # Compute similarity for all these chunks\n",
    "    sims = cosine_similarity([query_embedding], selected_chunk_embeddings)[0]\n",
    "\n",
    "    # Get top-K chunks overall\n",
    "    top_k_idx = sims.argsort()[::-1][:top_k_total]\n",
    "    results = []\n",
    "\n",
    "    for idx in top_k_idx:\n",
    "        results.append({\n",
    "            \"cluster\": cluster_labels[mask][idx],\n",
    "            \"context_id\": selected_df.iloc[idx][\"context_id\"],\n",
    "            \"chunk_id\": selected_df.iloc[idx][\"chunk_id\"],\n",
    "            \"title\": selected_df.iloc[idx][\"title\"],\n",
    "            \"chunk_embed_text\": selected_df.iloc[idx][\"chunk_embed_text\"],\n",
    "            \"chunk_start\": selected_df.iloc[idx][\"chunk_start\"],\n",
    "            \"chunk_end\": selected_df.iloc[idx][\"chunk_end\"],\n",
    "            \"similarity\": sims[idx]\n",
    "        })\n",
    "\n",
    "    return pd.DataFrame(results).sort_values(\"similarity\", ascending=False).reset_index(drop=True)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 67,
   "metadata": {},
   "outputs": [],
   "source": [
    "def retrieve_top_chunks_full(\n",
    "    query_embedding,\n",
    "    chunk_embeddings,\n",
    "    df_chunks,\n",
    "    top_k_chunks=10\n",
    "):\n",
    "    sims = cosine_similarity([query_embedding], chunk_embeddings)[0]\n",
    "    top_idx = sims.argsort()[::-1][:top_k_chunks]\n",
    "    \n",
    "    results = []\n",
    "    for idx in top_idx:\n",
    "        results.append({\n",
    "            \"context_id\": df_chunks.iloc[idx][\"context_id\"],\n",
    "            \"chunk_id\": df_chunks.iloc[idx][\"chunk_id\"],\n",
    "            \"title\": df_chunks.iloc[idx][\"title\"],\n",
    "            \"chunk_embed_text\": df_chunks.iloc[idx][\"chunk_embed_text\"],\n",
    "            \"chunk_start\": df_chunks.iloc[idx][\"chunk_start\"],\n",
    "            \"chunk_end\": df_chunks.iloc[idx][\"chunk_end\"],\n",
    "            \"similarity\": sims[idx]\n",
    "        })\n",
    "    \n",
    "    return pd.DataFrame(results).sort_values(\"similarity\", ascending=False)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 68,
   "metadata": {},
   "outputs": [],
   "source": [
    "# # ---------- Answer Containment ----------\n",
    "# def is_answer_in_chunk(chunk_text, answer_text):\n",
    "#     return answer_text.lower().strip() in chunk_text.lower()\n",
    "\n",
    "# def is_answer_in_chunk(chunk_text, answer_text):\n",
    "#     # Normalize\n",
    "#     chunk_tokens = set(re.findall(r\"\\w+\", chunk_text.lower()))\n",
    "#     answer_tokens = set(re.findall(r\"\\w+\", answer_text.lower()))\n",
    "\n",
    "#     # Require that most/all answer tokens are present\n",
    "#     return len(answer_tokens & chunk_tokens) / max(1, len(answer_tokens)) >= 0.8\n",
    "\n",
    "\n",
    "# from rapidfuzz import fuzz\n",
    "\n",
    "# def is_answer_in_chunk(chunk_text, answer_text, threshold=80):\n",
    "#     score = fuzz.partial_ratio(answer_text.lower(), chunk_text.lower())\n",
    "#     return score >= threshold\n",
    "\n",
    "def is_answer_in_chunk(answer_start, chunk_start, chunk_length):\n",
    "    if answer_start is None or chunk_start is None or chunk_length is None:\n",
    "        return False\n",
    "    return chunk_start <= answer_start < (chunk_start + chunk_length)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 69,
   "metadata": {},
   "outputs": [],
   "source": [
    "def compute_metrics_for_query(results, query_row, similarity_threshold=0.6):\n",
    "    # --- Check similarity threshold ---\n",
    "    if results.empty or results[\"similarity\"].max() < similarity_threshold:\n",
    "        results_filtered = pd.DataFrame([])  # Treat as no answer\n",
    "    else:\n",
    "        results_filtered = results\n",
    "\n",
    "    # --- Document-level ---\n",
    "    answer_exists = pd.notna(query_row[\"answer_start\"])\n",
    "    found_doc_id = False if results_filtered.empty else any(\n",
    "        query_row[\"context_id\"] == doc_id for doc_id in results_filtered[\"context_id\"]\n",
    "    )\n",
    "    y_true_doc = 1 if answer_exists else 0\n",
    "    y_pred_doc = 1 if found_doc_id else 0\n",
    "\n",
    "    # --- Chunk-level ---\n",
    "    if results_filtered.empty:\n",
    "        found_chunk_context = False\n",
    "        good_chunks = 0\n",
    "    else:\n",
    "        correct_doc_chunks = results_filtered[results_filtered[\"context_id\"] == query_row[\"context_id\"]]\n",
    "        found_chunk_context = any(\n",
    "            is_answer_in_chunk(\n",
    "                query_row[\"answer_start\"],\n",
    "                chunk[\"chunk_start\"],\n",
    "                chunk[\"chunk_end\"] - chunk[\"chunk_start\"]\n",
    "            )\n",
    "            for _, chunk in correct_doc_chunks.iterrows()\n",
    "        )\n",
    "        good_chunks = len(correct_doc_chunks)\n",
    "\n",
    "    total_chunks = results_filtered.shape[0] if not results_filtered.empty else 1\n",
    "    chunk_ratio = good_chunks / total_chunks\n",
    "\n",
    "    y_true_chunk = 1 if answer_exists else 0\n",
    "    y_pred_chunk = 1 if found_chunk_context else 0\n",
    "\n",
    "    return y_true_doc, y_pred_doc, y_true_chunk, y_pred_chunk, chunk_ratio"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 70,
   "metadata": {},
   "outputs": [],
   "source": [
    "# def evaluate_top_k_accuracy(\n",
    "#     df_queries,\n",
    "#     chunk_embeddings,\n",
    "#     df_chunks,\n",
    "#     cluster_labels,\n",
    "#     top_n_clusters=2,\n",
    "#     top_k_total=5\n",
    "# ):\n",
    "#     # âœ… Compute centroids once\n",
    "#     centroid_matrix, centroid_ids = compute_cluster_centroids(chunk_embeddings, cluster_labels)\n",
    "\n",
    "#     y_true_doc = []\n",
    "#     y_pred_doc = []\n",
    "\n",
    "#     y_true_chunk = []\n",
    "#     y_pred_chunk = []\n",
    "\n",
    "#     chunk_ratios = []\n",
    "\n",
    "#     for i, row in tqdm(df_queries.iterrows(), total=len(df_queries)):\n",
    "#         query_emb = model.encode([row[\"question\"]])[0]\n",
    "#         results = retrieve_top_chunks_by_cluster(\n",
    "#             query_embedding=query_emb,\n",
    "#             chunk_embeddings=chunk_embeddings,\n",
    "#             df_chunks=df_chunks,\n",
    "#             cluster_labels=cluster_labels,\n",
    "#             centroid_matrix=centroid_matrix,\n",
    "#             centroid_ids=centroid_ids,\n",
    "#             top_n_clusters=top_n_clusters,\n",
    "#             top_k_total=top_k_total\n",
    "#         )\n",
    "\n",
    "#         # Document-level\n",
    "#         found_doc_id = any(row[\"context_id\"] == doc_id for doc_id in results[\"context_id\"])\n",
    "#         y_true_doc.append(1)\n",
    "#         y_pred_doc.append(1 if found_doc_id else 0)\n",
    "\n",
    "#         correct_doc_chunks = results[results[\"context_id\"] == row[\"context_id\"]]\n",
    "#         found_chunk_context = any(\n",
    "#             is_answer_in_chunk(\n",
    "#                 row[\"answer_start\"],\n",
    "#                 chunk[\"chunk_start\"],\n",
    "#                 chunk[\"chunk_end\"] - chunk[\"chunk_start\"]\n",
    "#             )\n",
    "#             for _, chunk in correct_doc_chunks.iterrows()\n",
    "#         )\n",
    "#         good_chunks = len(correct_doc_chunks)\n",
    "#         total_chunks = results.shape[0]\n",
    "#         ratio = good_chunks / total_chunks\n",
    "#         chunk_ratios.append(ratio)\n",
    "\n",
    "#         y_true_chunk.append(1)\n",
    "#         y_pred_chunk.append(1 if found_chunk_context else 0)\n",
    "\n",
    "#     # Compute metrics\n",
    "#     chunk_accuracy = sum(chunk_ratios) / len(chunk_ratios) if len(chunk_ratios) > 0 else 0\n",
    "#     metrics = {\n",
    "#         \"doc_accuracy\": sum(y_pred_doc) / len(y_pred_doc),\n",
    "#         \"chunk_accuracy\": sum(y_pred_chunk) / len(y_pred_chunk),\n",
    "#         \"doc_precision\": precision_score(y_true_doc, y_pred_doc, zero_division=0),\n",
    "#         \"doc_recall\": recall_score(y_true_doc, y_pred_doc, zero_division=0),\n",
    "#         \"doc_f1\": f1_score(y_true_doc, y_pred_doc, zero_division=0),\n",
    "#         \"chunk_precision\": precision_score(y_true_chunk, y_pred_chunk, zero_division=0),\n",
    "#         \"chunk_recall\": recall_score(y_true_chunk, y_pred_chunk, zero_division=0),\n",
    "#         \"chunk_f1\": f1_score(y_true_chunk, y_pred_chunk, zero_division=0),\n",
    "#         \"correct_chunk_accuracy\": chunk_accuracy\n",
    "#     }\n",
    "\n",
    "#     return metrics\n",
    "def evaluate_top_k_accuracy(\n",
    "    df_queries,\n",
    "    chunk_embeddings,\n",
    "    df_chunks,\n",
    "    cluster_labels,\n",
    "    top_n_clusters=2,\n",
    "    top_k_total=5\n",
    "):\n",
    "    # Compute centroids once\n",
    "    centroid_matrix, centroid_ids = compute_cluster_centroids(chunk_embeddings, cluster_labels)\n",
    "\n",
    "    y_true_doc = []\n",
    "    y_pred_doc = []\n",
    "\n",
    "    y_true_chunk = []\n",
    "    y_pred_chunk = []\n",
    "\n",
    "    chunk_ratios = []\n",
    "    \n",
    "    # For 1024D embeddigs\n",
    "    sample_size = 2000\n",
    "    if len(df_queries) > sample_size:\n",
    "        df_queries = df_queries.sample(n=sample_size, random_state=42).reset_index(drop=True)\n",
    "    else:\n",
    "        df_queries = df_queries.reset_index(drop=True)\n",
    "\n",
    "    for _, row in tqdm(df_queries.iterrows(), total=len(df_queries)):\n",
    "        query_emb = model.encode([row[\"question\"]])[0]\n",
    "        results = retrieve_top_chunks_by_cluster(\n",
    "            query_embedding=query_emb,\n",
    "            chunk_embeddings=chunk_embeddings,\n",
    "            df_chunks=df_chunks,\n",
    "            cluster_labels=cluster_labels,\n",
    "            centroid_matrix=centroid_matrix,\n",
    "            centroid_ids=centroid_ids,\n",
    "            top_n_clusters=top_n_clusters,\n",
    "            top_k_total=top_k_total\n",
    "        )\n",
    "\n",
    "        ytd, ypd, ytc, ypc, cr = compute_metrics_for_query(results, row)\n",
    "        y_true_doc.append(ytd)\n",
    "        y_pred_doc.append(ypd)\n",
    "        y_true_chunk.append(ytc)\n",
    "        y_pred_chunk.append(ypc)\n",
    "        chunk_ratios.append(cr)\n",
    "\n",
    "    # Convert to arrays\n",
    "    y_true_doc_arr = np.array(y_true_doc)\n",
    "    y_pred_doc_arr = np.array(y_pred_doc)\n",
    "    y_true_chunk_arr = np.array(y_true_chunk)\n",
    "    y_pred_chunk_arr = np.array(y_pred_chunk)\n",
    "\n",
    "    # Compute metrics\n",
    "    chunk_accuracy = sum(chunk_ratios) / len(chunk_ratios) if len(chunk_ratios) > 0 else 0\n",
    "\n",
    "    metrics = {\n",
    "        \"doc_accuracy\": (y_pred_doc_arr == y_true_doc_arr).mean(),\n",
    "        \"chunk_accuracy\": (y_pred_chunk_arr == y_true_chunk_arr).mean(),\n",
    "        \"doc_precision\": precision_score(y_true_doc_arr, y_pred_doc_arr, zero_division=0),\n",
    "        \"doc_recall\": recall_score(y_true_doc_arr, y_pred_doc_arr, zero_division=0),\n",
    "        \"doc_f1\": f1_score(y_true_doc_arr, y_pred_doc_arr, zero_division=0),\n",
    "        \"chunk_precision\": precision_score(y_true_chunk_arr, y_pred_chunk_arr, zero_division=0),\n",
    "        \"chunk_recall\": recall_score(y_true_chunk_arr, y_pred_chunk_arr, zero_division=0),\n",
    "        \"chunk_f1\": f1_score(y_true_chunk_arr, y_pred_chunk_arr, zero_division=0),\n",
    "        \"correct_chunk_accuracy\": chunk_accuracy,\n",
    "        # True/False Positives/Negatives\n",
    "        \"doc_true_positives\": np.sum((y_pred_doc_arr == 1) & (y_true_doc_arr == 1)),\n",
    "        \"doc_true_negatives\": np.sum((y_pred_doc_arr == 0) & (y_true_doc_arr == 0)),\n",
    "        \"doc_false_positives\": np.sum((y_pred_doc_arr == 1) & (y_true_doc_arr == 0)),\n",
    "        \"doc_false_negatives\": np.sum((y_pred_doc_arr == 0) & (y_true_doc_arr == 1)),\n",
    "        \"chunk_true_positives\": np.sum((y_pred_chunk_arr == 1) & (y_true_chunk_arr == 1)),\n",
    "        \"chunk_true_negatives\": np.sum((y_pred_chunk_arr == 0) & (y_true_chunk_arr == 0)),\n",
    "        \"chunk_false_positives\": np.sum((y_pred_chunk_arr == 1) & (y_true_chunk_arr == 0)),\n",
    "        \"chunk_false_negatives\": np.sum((y_pred_chunk_arr == 0) & (y_true_chunk_arr == 1)),\n",
    "    }\n",
    "\n",
    "    return metrics\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 71,
   "metadata": {},
   "outputs": [],
   "source": [
    "# def evaluate_top_k_accuracy_full(df_queries, chunk_embeddings, df_chunks, top_k_chunks=5, similarity_threshold=0.6):\n",
    "    # y_true_doc = []\n",
    "    # y_pred_doc = []\n",
    "\n",
    "    # y_true_chunk = []\n",
    "    # y_pred_chunk = []\n",
    "\n",
    "    # chunk_ratios = []\n",
    "\n",
    "    # for i, row in tqdm(df_queries.iterrows(), total=len(df_queries)):\n",
    "    #     query_emb = model.encode([row[\"question\"]])[0]\n",
    "    #     results = retrieve_top_chunks_full(\n",
    "    #         query_embedding=query_emb,\n",
    "    #         chunk_embeddings=chunk_embeddings,\n",
    "    #         df_chunks=df_chunks,\n",
    "    #         top_k_chunks=top_k_chunks\n",
    "    #     )\n",
    "\n",
    "    #     # Document-level\n",
    "    #     found_doc_id = any(row[\"context_id\"] == doc_id for doc_id in results[\"context_id\"])\n",
    "    #     y_true_doc.append(1)\n",
    "    #     y_pred_doc.append(1 if found_doc_id else 0)\n",
    "\n",
    "    #     correct_doc_chunks = results[results[\"context_id\"] == row[\"context_id\"]]\n",
    "    #     found_chunk_context = any(\n",
    "    #         is_answer_in_chunk(\n",
    "    #             row[\"answer_start\"],\n",
    "    #             chunk[\"chunk_start\"],\n",
    "    #             chunk[\"chunk_end\"] - chunk[\"chunk_start\"]\n",
    "    #         )\n",
    "    #         for _, chunk in correct_doc_chunks.iterrows()\n",
    "    #     )\n",
    "    #     good_chunks = len(correct_doc_chunks)\n",
    "    #     total_chunks = results.shape[0]\n",
    "    #     ratio = good_chunks / total_chunks\n",
    "    #     chunk_ratios.append(ratio)\n",
    "\n",
    "    #     y_true_chunk.append(1)\n",
    "    #     y_pred_chunk.append(1 if found_chunk_context else 0)\n",
    "\n",
    "    # # Compute metrics\n",
    "    # chunk_accuracy = sum(chunk_ratios) / len(chunk_ratios) if len(chunk_ratios) > 0 else 0\n",
    "    # metrics = {\n",
    "    #     \"doc_accuracy\": sum(y_pred_doc) / len(y_pred_doc),\n",
    "    #     \"chunk_accuracy\": sum(y_pred_chunk) / len(y_pred_chunk),\n",
    "    #     \"doc_precision\": precision_score(y_true_doc, y_pred_doc, zero_division=0),\n",
    "    #     \"doc_recall\": recall_score(y_true_doc, y_pred_doc, zero_division=0),\n",
    "    #     \"doc_f1\": f1_score(y_true_doc, y_pred_doc, zero_division=0),\n",
    "    #     \"chunk_precision\": precision_score(y_true_chunk, y_pred_chunk, zero_division=0),\n",
    "    #     \"chunk_recall\": recall_score(y_true_chunk, y_pred_chunk, zero_division=0),\n",
    "    #     \"chunk_f1\": f1_score(y_true_chunk, y_pred_chunk, zero_division=0),\n",
    "    #     \"correct_chunk_accuracy\": chunk_accuracy\n",
    "    # }\n",
    "\n",
    "    # return metrics\n",
    "def evaluate_top_k_accuracy_full(df_queries, chunk_embeddings, df_chunks, top_k_chunks=5):\n",
    "    y_true_doc = []\n",
    "    y_pred_doc = []\n",
    "\n",
    "    y_true_chunk = []\n",
    "    y_pred_chunk = []\n",
    "\n",
    "    chunk_ratios = []\n",
    "    \n",
    "    # For 1024D embeddigs\n",
    "    sample_size = 2000\n",
    "    if len(df_queries) > sample_size:\n",
    "        df_queries = df_queries.sample(n=sample_size, random_state=42).reset_index(drop=True)\n",
    "    else:\n",
    "        df_queries = df_queries.reset_index(drop=True)\n",
    "    \n",
    "\n",
    "    for _, row in tqdm(df_queries.iterrows(), total=len(df_queries)):\n",
    "        query_emb = model.encode([row[\"question\"]])[0]\n",
    "        results = retrieve_top_chunks_full(\n",
    "            query_embedding=query_emb,\n",
    "            chunk_embeddings=chunk_embeddings,\n",
    "            df_chunks=df_chunks,\n",
    "            top_k_chunks=top_k_chunks\n",
    "        )\n",
    "\n",
    "        ytd, ypd, ytc, ypc, cr = compute_metrics_for_query(results, row)\n",
    "        y_true_doc.append(ytd)\n",
    "        y_pred_doc.append(ypd)\n",
    "        y_true_chunk.append(ytc)\n",
    "        y_pred_chunk.append(ypc)\n",
    "        chunk_ratios.append(cr)\n",
    "\n",
    "    # Convert to arrays\n",
    "    y_true_doc_arr = np.array(y_true_doc)\n",
    "    y_pred_doc_arr = np.array(y_pred_doc)\n",
    "    y_true_chunk_arr = np.array(y_true_chunk)\n",
    "    y_pred_chunk_arr = np.array(y_pred_chunk)\n",
    "\n",
    "    # Compute metrics\n",
    "    chunk_accuracy = sum(chunk_ratios) / len(chunk_ratios) if len(chunk_ratios) > 0 else 0\n",
    "\n",
    "    metrics = {\n",
    "        \"doc_accuracy\": (y_pred_doc_arr == y_true_doc_arr).mean(),\n",
    "        \"chunk_accuracy\": (y_pred_chunk_arr == y_true_chunk_arr).mean(),\n",
    "        \"doc_precision\": precision_score(y_true_doc_arr, y_pred_doc_arr, zero_division=0),\n",
    "        \"doc_recall\": recall_score(y_true_doc_arr, y_pred_doc_arr, zero_division=0),\n",
    "        \"doc_f1\": f1_score(y_true_doc_arr, y_pred_doc_arr, zero_division=0),\n",
    "        \"chunk_precision\": precision_score(y_true_chunk_arr, y_pred_chunk_arr, zero_division=0),\n",
    "        \"chunk_recall\": recall_score(y_true_chunk_arr, y_pred_chunk_arr, zero_division=0),\n",
    "        \"chunk_f1\": f1_score(y_true_chunk_arr, y_pred_chunk_arr, zero_division=0),\n",
    "        \"correct_chunk_accuracy\": chunk_accuracy,\n",
    "        # True/False Positives/Negatives\n",
    "        \"doc_true_positives\": np.sum((y_pred_doc_arr == 1) & (y_true_doc_arr == 1)),\n",
    "        \"doc_true_negatives\": np.sum((y_pred_doc_arr == 0) & (y_true_doc_arr == 0)),\n",
    "        \"doc_false_positives\": np.sum((y_pred_doc_arr == 1) & (y_true_doc_arr == 0)),\n",
    "        \"doc_false_negatives\": np.sum((y_pred_doc_arr == 0) & (y_true_doc_arr == 1)),\n",
    "        \"chunk_true_positives\": np.sum((y_pred_chunk_arr == 1) & (y_true_chunk_arr == 1)),\n",
    "        \"chunk_true_negatives\": np.sum((y_pred_chunk_arr == 0) & (y_true_chunk_arr == 0)),\n",
    "        \"chunk_false_positives\": np.sum((y_pred_chunk_arr == 1) & (y_true_chunk_arr == 0)),\n",
    "        \"chunk_false_negatives\": np.sum((y_pred_chunk_arr == 0) & (y_true_chunk_arr == 1)),\n",
    "    }\n",
    "\n",
    "    return metrics"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 72,
   "metadata": {},
   "outputs": [],
   "source": [
    "def minibatchkmeans_retrieval_evaluation(\n",
    "    chunk_embeddings,\n",
    "    df_chunks,\n",
    "    df_queries,\n",
    "    n_clusters=20,\n",
    "    batch_size=2000,\n",
    "    top_k_total=10,\n",
    "    init_fraction=0.5,  # fraction of data used for initialization\n",
    "    top_n_clusters=10\n",
    "):\n",
    "    \"\"\"\n",
    "    MiniBatchKMeans clustering + retrieval evaluation on a growing dataset.\n",
    "    Simulates online learning via incremental partial_fit updates.\n",
    "    Evaluates only on the chunks that have been clustered so far.\n",
    "    \"\"\"\n",
    "    queries_context_ids = df_queries['context_id'].unique()\n",
    "    chunk_context_ids = df_chunks['context_id'].unique()\n",
    "    missing_context_ids = set(queries_context_ids) - set(chunk_context_ids)\n",
    "    \n",
    "    n_samples = chunk_embeddings.shape[0]\n",
    "    init_size = int(n_samples * init_fraction)\n",
    "    remaining_size = n_samples - init_size\n",
    "    n_batches = int(np.ceil(remaining_size / batch_size))\n",
    "\n",
    "    # --- Step 1: Initialization ---\n",
    "    print(f\"ðŸ”§ Using {init_fraction*100:.0f}% of data ({init_size} samples) for initialization\")\n",
    "    init_start = time.time()\n",
    "    kmeans = MiniBatchKMeans(\n",
    "        n_clusters=n_clusters,\n",
    "        random_state=42,\n",
    "        batch_size=batch_size\n",
    "    )\n",
    "    kmeans.partial_fit(chunk_embeddings[:init_size])\n",
    "    init_end = time.time()\n",
    "    init_time = init_end - init_start\n",
    "    print(f\"âœ… Initialization done in {init_time:.4f} s\")\n",
    "\n",
    "    # --- Step 2: Online updates on the remaining data ---\n",
    "    results = []\n",
    "    for batch_idx in tqdm(range(1, n_batches + 1)):\n",
    "        start_idx = (batch_idx - 1) * batch_size\n",
    "        end_idx = min(batch_idx * batch_size, remaining_size)\n",
    "        batch_embeddings = chunk_embeddings[init_size + start_idx : init_size + end_idx]\n",
    "\n",
    "        # --- Online update (MiniBatchKMeans incremental fit) ---\n",
    "        update_start = time.time()\n",
    "        kmeans.partial_fit(batch_embeddings)\n",
    "        update_end = time.time()\n",
    "        update_time = update_end - update_start\n",
    "\n",
    "        # --- Only evaluate on seen data so far ---\n",
    "        seen_end_idx = init_size + end_idx\n",
    "        seen_embeddings = chunk_embeddings[:seen_end_idx]\n",
    "        seen_df_chunks = df_chunks.iloc[:seen_end_idx].reset_index(drop=True)\n",
    "\n",
    "        # --- Predict cluster labels for seen data ---\n",
    "        labels_seen = kmeans.predict(seen_embeddings)\n",
    "\n",
    "        # --- Progressive query inclusion ---\n",
    "        progress = batch_idx / n_batches\n",
    "        queries_in_seen = df_queries[df_queries[\"context_id\"].isin(seen_df_chunks[\"context_id\"].unique())]\n",
    "        queries_not_in_seen = df_queries[df_queries[\"context_id\"].isin(missing_context_ids)]\n",
    "        n_to_sample = int(len(queries_not_in_seen) * progress)\n",
    "        queries_sampled = (\n",
    "            queries_not_in_seen.sample(n=n_to_sample, random_state=42)\n",
    "            if n_to_sample > 0 else pd.DataFrame(columns=df_queries.columns)\n",
    "        )\n",
    "        df_queries_seen = pd.concat([queries_in_seen, queries_sampled]).reset_index(drop=True)\n",
    "\n",
    "        # --- Retrieval accuracy ---\n",
    "        retrieval_start = time.time()\n",
    "        metrics = evaluate_top_k_accuracy(\n",
    "            df_queries=df_queries_seen,\n",
    "            chunk_embeddings=seen_embeddings,\n",
    "            df_chunks=seen_df_chunks,\n",
    "            cluster_labels=labels_seen,\n",
    "            top_n_clusters=top_n_clusters,\n",
    "            top_k_total=top_k_total\n",
    "        )\n",
    "        retrieval_end = time.time()\n",
    "        retrieval_time = retrieval_end - retrieval_start\n",
    "\n",
    "        # --- Log results ---\n",
    "        results.append({\n",
    "            \"batch\": batch_idx,\n",
    "            \"init_time\": init_time if batch_idx == 1 else 0,\n",
    "            \"update_time\": update_time,\n",
    "            \"retrieval_time\": retrieval_time,\n",
    "            \"metrics\": metrics,\n",
    "            \"n_clusters\": n_clusters\n",
    "        })\n",
    "        results_df = pd.DataFrame(results)\n",
    "        results_df.to_excel(\"../data/results/onlinekmeans_with_minibatchkmeans_v4.xlsx\")\n",
    "\n",
    "    return pd.DataFrame(results)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 73,
   "metadata": {},
   "outputs": [],
   "source": [
    "def online_kmeans_retrieval_evaluation(\n",
    "    chunk_embeddings,\n",
    "    df_chunks,\n",
    "    df_queries,\n",
    "    n_clusters=20,\n",
    "    batch_size=500,\n",
    "    top_k_total=5,\n",
    "    init_fraction=0.5,  # fraction of data used for initialization\n",
    "    max_clusters=None,\n",
    "    metric=\"cosine\",\n",
    "    new_cluster_threshold=None,\n",
    "    merge_threshold=None,\n",
    "    decay=None,\n",
    "    top_n_clusters=10\n",
    "):\n",
    "    \"\"\"\n",
    "    OnlineKMeans clustering + retrieval evaluation on growing dataset.\n",
    "    Only evaluates on the chunks that have been clustered so far.\n",
    "    \"\"\"\n",
    "    queries_context_ids = df_queries['context_id'].unique()\n",
    "    chunk_context_ids = df_chunks['context_id'].unique()\n",
    "    missing_context_ids = set(queries_context_ids) - set(chunk_context_ids)\n",
    "    \n",
    "    n_samples = chunk_embeddings.shape[0]\n",
    "    init_size = int(n_samples * init_fraction)\n",
    "    remaining_size = n_samples - init_size\n",
    "    n_batches = int(np.ceil(remaining_size / batch_size))\n",
    "\n",
    "    # --- Step 1: Initialization ---\n",
    "    print(f\"ðŸ”§ Using {init_fraction*100:.0f}% of data ({init_size} samples) for initialization\")\n",
    "    init_start = time.time()\n",
    "    okm = OnlineKMeans(\n",
    "        n_clusters=n_clusters,\n",
    "        max_clusters=max_clusters,\n",
    "        metric=metric,\n",
    "        new_cluster_threshold=new_cluster_threshold,\n",
    "        merge_threshold=merge_threshold,\n",
    "        random_state=42,\n",
    "        decay=decay\n",
    "    )\n",
    "    okm.partial_fit(chunk_embeddings[:init_size])\n",
    "    init_end = time.time()\n",
    "    init_time = init_end - init_start\n",
    "    print(f\"âœ… Initialization done in {init_time:.4f} s\")\n",
    "\n",
    "    # --- Step 2: Online updates on the remaining data ---\n",
    "    results = []\n",
    "    for batch_idx in tqdm(range(1, int(np.ceil(remaining_size / batch_size)) + 1)):\n",
    "        start_idx = (batch_idx - 1) * batch_size\n",
    "        end_idx = min(batch_idx * batch_size, remaining_size)\n",
    "        batch_embeddings = chunk_embeddings[init_size + start_idx : init_size + end_idx]\n",
    "\n",
    "        # --- Online update ---\n",
    "        update_start = time.time()\n",
    "        okm.partial_fit(batch_embeddings)\n",
    "        update_end = time.time()\n",
    "        update_time = update_end - update_start\n",
    "\n",
    "        # --- Only evaluate on seen data so far ---\n",
    "        seen_end_idx = init_size + end_idx\n",
    "        seen_embeddings = chunk_embeddings[:seen_end_idx]\n",
    "        seen_df_chunks = df_chunks.iloc[:seen_end_idx].reset_index(drop=True)\n",
    "\n",
    "        # --- Predict cluster labels for seen data ---\n",
    "        labels_seen = okm.predict(seen_embeddings)\n",
    "\n",
    "        progress = batch_idx / n_batches\n",
    "        queries_in_seen = df_queries[df_queries[\"context_id\"].isin(seen_df_chunks[\"context_id\"].unique())]\n",
    "        queries_not_in_seen = df_queries[(df_queries[\"context_id\"].isin(missing_context_ids))]\n",
    "        n_to_sample = int(len(queries_not_in_seen) * progress)\n",
    "        queries_sampled = queries_not_in_seen.sample(n=n_to_sample, random_state=42) if n_to_sample > 0 else pd.DataFrame(columns=df_queries.columns)\n",
    "        df_queries_seen = pd.concat([queries_in_seen, queries_sampled]).reset_index(drop=True)\n",
    "        \n",
    "        # --- Retrieval accuracy ---\n",
    "        retrieval_start = time.time()\n",
    "        metrics = evaluate_top_k_accuracy(\n",
    "            df_queries=df_queries_seen,\n",
    "            chunk_embeddings=seen_embeddings,\n",
    "            df_chunks=seen_df_chunks,\n",
    "            cluster_labels=labels_seen,\n",
    "            top_n_clusters=top_n_clusters,\n",
    "            top_k_total=top_k_total\n",
    "        )\n",
    "        retrieval_end = time.time()\n",
    "        retrieval_time = retrieval_end - retrieval_start\n",
    "\n",
    "        results.append({\n",
    "            \"batch\": batch_idx,\n",
    "            \"init_time\": init_time if batch_idx == 1 else 0,\n",
    "            \"update_time\": update_time,\n",
    "            \"retrieval_time\": retrieval_time,\n",
    "            \"metrics\": metrics,\n",
    "            \"n_clusters\": len(okm.centroids)\n",
    "        })\n",
    "        results_df = pd.DataFrame(results)\n",
    "        results_df.to_excel(\"../data/results/onlinekmeans_v4_from.xlsx\")\n",
    "\n",
    "        #print(f\"[Batch {batch_idx}] Seen chunks: {seen_end_idx}, Doc acc: {metrics['doc_accuracy']:.4f}, Chunk acc: {metrics['chunk_accuracy']:.4f}, Clusters: {len(okm.centroids)}\")\n",
    "\n",
    "    return pd.DataFrame(results)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 74,
   "metadata": {},
   "outputs": [],
   "source": [
    "def kmeans_retrieval_evaluation(\n",
    "    chunk_embeddings,\n",
    "    df_chunks,\n",
    "    df_queries,\n",
    "    n_clusters=20,\n",
    "    batch_size=500,\n",
    "    top_k_total=5,\n",
    "    init_fraction=0.5,  # fraction of data used for initialization\n",
    "    top_n_clusters=10\n",
    "):\n",
    "    \"\"\"\n",
    "    Batch KMeans clustering + retrieval evaluation on growing dataset.\n",
    "    Re-fits KMeans from scratch after each batch to simulate online learning.\n",
    "    \"\"\"\n",
    "    queries_context_ids = df_queries['context_id'].unique()\n",
    "    chunk_context_ids = df_chunks['context_id'].unique()\n",
    "    missing_context_ids = set(queries_context_ids) - set(chunk_context_ids)\n",
    "    \n",
    "    n_samples = chunk_embeddings.shape[0]\n",
    "    init_size = int(n_samples * init_fraction)\n",
    "    remaining_size = n_samples - init_size\n",
    "    n_batches = int(np.ceil(remaining_size / batch_size))\n",
    "\n",
    "    # --- Step 1: Initialization ---\n",
    "    print(f\"ðŸ”§ Using {init_fraction*100:.0f}% of data ({init_size} samples) for initialization\")\n",
    "    init_start = time.time()\n",
    "    kmeans = KMeans(n_clusters=n_clusters, random_state=42)\n",
    "    kmeans.fit(chunk_embeddings[:init_size])\n",
    "    init_end = time.time()\n",
    "    init_time = init_end - init_start\n",
    "    print(f\"âœ… Initialization done in {init_time:.4f} s\")\n",
    "\n",
    "    # --- Step 2: Batch updates (re-fit each time on seen data) ---\n",
    "    results = []\n",
    "    for batch_idx in tqdm(range(1, n_batches + 1)):\n",
    "        start_idx = (batch_idx - 1) * batch_size\n",
    "        end_idx = min(batch_idx * batch_size, remaining_size)\n",
    "        seen_end_idx = init_size + end_idx\n",
    "\n",
    "        # --- Fit KMeans on all seen data so far ---\n",
    "        seen_embeddings = chunk_embeddings[:seen_end_idx]\n",
    "        seen_df_chunks = df_chunks.iloc[:seen_end_idx].reset_index(drop=True)\n",
    "\n",
    "        update_start = time.time()\n",
    "        kmeans = KMeans(n_clusters=n_clusters, random_state=42)\n",
    "        kmeans.fit(seen_embeddings)\n",
    "        update_end = time.time()\n",
    "        update_time = update_end - update_start\n",
    "\n",
    "        labels_seen = kmeans.labels_\n",
    "\n",
    "        # --- Progress based on batch number ---\n",
    "        progress = batch_idx / n_batches\n",
    "\n",
    "        # --- Query selection ---\n",
    "        queries_in_seen = df_queries[df_queries[\"context_id\"].isin(seen_df_chunks[\"context_id\"].unique())]\n",
    "        queries_not_in_seen = df_queries[df_queries[\"context_id\"].isin(missing_context_ids)]\n",
    "        n_to_sample = int(len(queries_not_in_seen) * progress)\n",
    "        queries_sampled = (\n",
    "            queries_not_in_seen.sample(n=n_to_sample, random_state=42)\n",
    "            if n_to_sample > 0 else pd.DataFrame(columns=df_queries.columns)\n",
    "        )\n",
    "        df_queries_seen = pd.concat([queries_in_seen, queries_sampled]).reset_index(drop=True)\n",
    "\n",
    "        # --- Retrieval accuracy ---\n",
    "        retrieval_start = time.time()\n",
    "        metrics = evaluate_top_k_accuracy(\n",
    "            df_queries=df_queries_seen,\n",
    "            chunk_embeddings=seen_embeddings,\n",
    "            df_chunks=seen_df_chunks,\n",
    "            cluster_labels=labels_seen,\n",
    "            top_n_clusters=top_n_clusters,\n",
    "            top_k_total=top_k_total\n",
    "        )\n",
    "        retrieval_end = time.time()\n",
    "        retrieval_time = retrieval_end - retrieval_start\n",
    "\n",
    "        results.append({\n",
    "            \"batch\": batch_idx,\n",
    "            \"init_time\": init_time if batch_idx == 1 else 0,\n",
    "            \"update_time\": update_time,\n",
    "            \"retrieval_time\": retrieval_time,\n",
    "            \"metrics\": metrics,\n",
    "            \"n_clusters\": n_clusters\n",
    "        })\n",
    "        results_df = pd.DataFrame(results)\n",
    "        results_df.to_excel(\"../data/results/onlinekmeans_with_kmeans_v4.xlsx\")\n",
    "\n",
    "    return pd.DataFrame(results)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 75,
   "metadata": {},
   "outputs": [],
   "source": [
    "# def river_retrieval_evaluation(\n",
    "#     chunk_embeddings,\n",
    "#     df_chunks,\n",
    "#     df_queries,\n",
    "#     n_clusters=10,\n",
    "#     batch_size=2000,\n",
    "#     top_k_total=10,\n",
    "#     init_fraction=0.5,\n",
    "#     top_n_clusters=10\n",
    "# ):\n",
    "#     \"\"\"\n",
    "#     Uses River's online clustering (streaming KMeans) + retrieval evaluation on growing dataset.\n",
    "#     Evaluates progressively as more chunks are clustered.\n",
    "#     \"\"\"\n",
    "#     queries_context_ids = df_queries['context_id'].unique()\n",
    "#     chunk_context_ids = df_chunks['context_id'].unique()\n",
    "#     missing_context_ids = set(queries_context_ids) - set(chunk_context_ids)\n",
    "    \n",
    "#     n_samples = chunk_embeddings.shape[0]\n",
    "#     init_size = int(n_samples * init_fraction)\n",
    "#     remaining_size = n_samples - init_size\n",
    "#     n_batches = int(np.ceil(remaining_size / batch_size))\n",
    "\n",
    "#     print(f\"ðŸ”§ Using {init_fraction*100:.0f}% of data ({init_size} samples) for initialization\")\n",
    "\n",
    "#     # âœ… Convert embeddings to dict once for speed\n",
    "#     print(\"âš™ï¸ Converting embeddings to River-friendly dict format...\")\n",
    "#     emb_dicts = [{i: float(v) for i, v in enumerate(emb)} for emb in chunk_embeddings]\n",
    "#     print(\"âœ… Conversion done.\")\n",
    "\n",
    "#     # Initialize River KMeans\n",
    "#     stream_clusterer = cluster.KMeans(n_clusters=n_clusters, halflife=0.001, sigma=3, seed=42)\n",
    "\n",
    "#     # --- Initialization ---\n",
    "#     init_start = time.time()\n",
    "#     for emb_dict in emb_dicts[:init_size]:\n",
    "#         stream_clusterer.learn_one(emb_dict)\n",
    "#     init_end = time.time()\n",
    "#     init_time = init_end - init_start\n",
    "#     print(f\"âœ… Initialization done in {init_time:.4f} s\")\n",
    "\n",
    "#     results = []\n",
    "#     for batch_idx in tqdm(range(1, n_batches + 1), desc=\"Batches\"):\n",
    "#         start_idx = (batch_idx - 1) * batch_size\n",
    "#         end_idx = min(batch_idx * batch_size, remaining_size)\n",
    "#         batch_dicts = emb_dicts[init_size + start_idx : init_size + end_idx]\n",
    "\n",
    "#         # --- Online update ---\n",
    "#         update_start = time.time()\n",
    "#         for emb_dict in batch_dicts:\n",
    "#             stream_clusterer.learn_one(emb_dict)\n",
    "#         update_end = time.time()\n",
    "#         update_time = update_end - update_start\n",
    "\n",
    "#         # --- Evaluate on seen data ---\n",
    "#         seen_end_idx = init_size + end_idx\n",
    "#         seen_embeddings = chunk_embeddings[:seen_end_idx]\n",
    "#         seen_df_chunks = df_chunks.iloc[:seen_end_idx].reset_index(drop=True)\n",
    "\n",
    "#         # --- Predict cluster labels for seen data ---\n",
    "#         labels_seen = [stream_clusterer.predict_one(emb_dict) for emb_dict in emb_dicts[:seen_end_idx]]\n",
    "\n",
    "#         # --- Progressive inclusion of unseen queries ---\n",
    "#         progress = batch_idx / n_batches\n",
    "#         queries_in_seen = df_queries[df_queries[\"context_id\"].isin(seen_df_chunks[\"context_id\"].unique())]\n",
    "#         queries_not_in_seen = df_queries[df_queries[\"context_id\"].isin(missing_context_ids)]\n",
    "#         n_to_sample = int(len(queries_not_in_seen) * progress)\n",
    "#         queries_sampled = (\n",
    "#             queries_not_in_seen.sample(n=n_to_sample, random_state=42)\n",
    "#             if n_to_sample > 0 else pd.DataFrame(columns=df_queries.columns)\n",
    "#         )\n",
    "#         df_queries_seen = pd.concat([queries_in_seen, queries_sampled]).reset_index(drop=True)\n",
    "\n",
    "#         # --- Retrieval accuracy ---\n",
    "#         retrieval_start = time.time()\n",
    "#         metrics = evaluate_top_k_accuracy(\n",
    "#             df_queries=df_queries_seen,\n",
    "#             chunk_embeddings=seen_embeddings,\n",
    "#             df_chunks=seen_df_chunks,\n",
    "#             cluster_labels=labels_seen,\n",
    "#             top_n_clusters=top_n_clusters,\n",
    "#             top_k_total=top_k_total\n",
    "#         )\n",
    "#         retrieval_end = time.time()\n",
    "#         retrieval_time = retrieval_end - retrieval_start\n",
    "\n",
    "#         # --- Log results ---\n",
    "#         results.append({\n",
    "#             \"batch\": batch_idx,\n",
    "#             \"init_time\": init_time if batch_idx == 1 else 0,\n",
    "#             \"update_time\": update_time,\n",
    "#             \"retrieval_time\": retrieval_time,\n",
    "#             \"metrics\": metrics,\n",
    "#             \"n_clusters\": len(stream_clusterer.centers)\n",
    "#         })\n",
    "\n",
    "#         results_df = pd.DataFrame(results)\n",
    "#         results_df.to_excel(\"../data/results/river_kmeans_stream_v4.xlsx\", index=False)\n",
    "\n",
    "#     return pd.DataFrame(results)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 76,
   "metadata": {},
   "outputs": [],
   "source": [
    "def retrieve_top_chunks_faiss(\n",
    "    query_embedding,\n",
    "    faiss_index,\n",
    "    df_chunks,\n",
    "    top_k_chunks=10\n",
    "):\n",
    "    query_vec = np.array(query_embedding).astype('float32').reshape(1, -1)\n",
    "    \n",
    "    distances, indices = faiss_index.search(query_vec, top_k_chunks)\n",
    "\n",
    "    if isinstance(faiss_index, faiss.IndexFlatL2):\n",
    "        similarities = -distances[0]\n",
    "    else:\n",
    "        similarities = distances[0]\n",
    "    \n",
    "    # Collect results\n",
    "    results = []\n",
    "    for i, idx in enumerate(indices[0]):\n",
    "        chunk = df_chunks.iloc[idx]\n",
    "        results.append({\n",
    "            \"context_id\": chunk[\"context_id\"],\n",
    "            \"chunk_id\": chunk[\"chunk_id\"],\n",
    "            \"title\": chunk[\"title\"],\n",
    "            \"chunk_embed_text\": chunk[\"chunk_embed_text\"],\n",
    "            \"chunk_start\": chunk[\"chunk_start\"],\n",
    "            \"chunk_end\": chunk[\"chunk_end\"],\n",
    "            \"similarity\": float(similarities[i])\n",
    "        })\n",
    "\n",
    "    return pd.DataFrame(results).sort_values(\"similarity\", ascending=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 77,
   "metadata": {},
   "outputs": [],
   "source": [
    "def evaluate_top_k_accuracy_faiss(df_queries, faiss_index, df_chunks, top_k_chunks=5, similarity_threshold=0.6):\n",
    "    y_true_doc = []\n",
    "    y_pred_doc = []\n",
    "\n",
    "    y_true_chunk = []\n",
    "    y_pred_chunk = []\n",
    "\n",
    "    chunk_ratios = []\n",
    "    \n",
    "    # For 1024D embeddigs\n",
    "    sample_size = 2000\n",
    "    if len(df_queries) > sample_size:\n",
    "        df_queries = df_queries.sample(n=sample_size, random_state=42).reset_index(drop=True)\n",
    "    else:\n",
    "        df_queries = df_queries.reset_index(drop=True)\n",
    "\n",
    "    for _, row in tqdm(df_queries.iterrows(), total=len(df_queries)):\n",
    "        query_emb = model.encode([row[\"question\"]])[0]\n",
    "        results = retrieve_top_chunks_faiss(\n",
    "            query_embedding=query_emb,\n",
    "            faiss_index=faiss_index,\n",
    "            df_chunks=df_chunks,\n",
    "            top_k_chunks=top_k_chunks\n",
    "        )\n",
    "\n",
    "        ytd, ypd, ytc, ypc, cr = compute_metrics_for_query(results, row, similarity_threshold)\n",
    "        y_true_doc.append(ytd)\n",
    "        y_pred_doc.append(ypd)\n",
    "        y_true_chunk.append(ytc)\n",
    "        y_pred_chunk.append(ypc)\n",
    "        chunk_ratios.append(cr)    \n",
    "\n",
    "\n",
    "    # Convert to arrays\n",
    "    y_true_doc_arr = np.array(y_true_doc)\n",
    "    y_pred_doc_arr = np.array(y_pred_doc)\n",
    "    y_true_chunk_arr = np.array(y_true_chunk)\n",
    "    y_pred_chunk_arr = np.array(y_pred_chunk)\n",
    "\n",
    "    # Compute metrics\n",
    "    chunk_accuracy = sum(chunk_ratios) / len(chunk_ratios) if len(chunk_ratios) > 0 else 0\n",
    "\n",
    "    metrics = {\n",
    "        \"doc_accuracy\": (y_pred_doc_arr == y_true_doc_arr).mean(),\n",
    "        \"chunk_accuracy\": (y_pred_chunk_arr == y_true_chunk_arr).mean(),\n",
    "        \"doc_precision\": precision_score(y_true_doc_arr, y_pred_doc_arr, zero_division=0),\n",
    "        \"doc_recall\": recall_score(y_true_doc_arr, y_pred_doc_arr, zero_division=0),\n",
    "        \"doc_f1\": f1_score(y_true_doc_arr, y_pred_doc_arr, zero_division=0),\n",
    "        \"chunk_precision\": precision_score(y_true_chunk_arr, y_pred_chunk_arr, zero_division=0),\n",
    "        \"chunk_recall\": recall_score(y_true_chunk_arr, y_pred_chunk_arr, zero_division=0),\n",
    "        \"chunk_f1\": f1_score(y_true_chunk_arr, y_pred_chunk_arr, zero_division=0),\n",
    "        \"correct_chunk_accuracy\": chunk_accuracy,\n",
    "        # True/False Positives/Negatives\n",
    "        \"doc_true_positives\": np.sum((y_pred_doc_arr == 1) & (y_true_doc_arr == 1)),\n",
    "        \"doc_true_negatives\": np.sum((y_pred_doc_arr == 0) & (y_true_doc_arr == 0)),\n",
    "        \"doc_false_positives\": np.sum((y_pred_doc_arr == 1) & (y_true_doc_arr == 0)),\n",
    "        \"doc_false_negatives\": np.sum((y_pred_doc_arr == 0) & (y_true_doc_arr == 1)),\n",
    "        \"chunk_true_positives\": np.sum((y_pred_chunk_arr == 1) & (y_true_chunk_arr == 1)),\n",
    "        \"chunk_true_negatives\": np.sum((y_pred_chunk_arr == 0) & (y_true_chunk_arr == 0)),\n",
    "        \"chunk_false_positives\": np.sum((y_pred_chunk_arr == 1) & (y_true_chunk_arr == 0)),\n",
    "        \"chunk_false_negatives\": np.sum((y_pred_chunk_arr == 0) & (y_true_chunk_arr == 1)),\n",
    "    }\n",
    "\n",
    "    return metrics"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 78,
   "metadata": {},
   "outputs": [],
   "source": [
    "def faiss_retrieval_evaluation(\n",
    "    chunk_embeddings,\n",
    "    df_chunks,\n",
    "    df_queries,\n",
    "    batch_size=2000,\n",
    "    top_k_total=10,\n",
    "    init_fraction=0.5,   # fraction of data used for initialization\n",
    "    metric=\"cosine\"\n",
    "):\n",
    "    # --- Step 0: Setup ---\n",
    "    queries_context_ids = df_queries['context_id'].unique()\n",
    "    chunk_context_ids = df_chunks['context_id'].unique()\n",
    "    missing_context_ids = set(queries_context_ids) - set(chunk_context_ids)\n",
    "\n",
    "    n_samples = chunk_embeddings.shape[0]\n",
    "    init_size = int(n_samples * init_fraction)\n",
    "    remaining_size = n_samples - init_size\n",
    "    n_batches = int(np.ceil(remaining_size / batch_size))\n",
    "\n",
    "    # --- Step 1: Initialization ---\n",
    "    print(f\"ðŸ”§ Using {init_fraction*100:.0f}% of data ({init_size} samples) for FAISS initialization\")\n",
    "\n",
    "    d = chunk_embeddings.shape[1]\n",
    "    if metric == \"cosine\":\n",
    "        faiss.normalize_L2(chunk_embeddings)\n",
    "        M = 32\n",
    "        index = faiss.IndexHNSWFlat(d, M, faiss.METRIC_INNER_PRODUCT)\n",
    "        index.hnsw.efConstruction = 150\n",
    "        index.hnsw.efSearch = 16  \n",
    "    else:\n",
    "        M = 32\n",
    "        index = faiss.IndexHNSWFlat(d, M, faiss.METRIC_INNER_PRODUCT)\n",
    "        index.hnsw.efConstruction = 150\n",
    "        index.hnsw.efSearch = 16\n",
    "\n",
    "    init_start = time.time()\n",
    "    index.add(chunk_embeddings[:init_size])\n",
    "    init_end = time.time()\n",
    "    init_time = init_end - init_start\n",
    "\n",
    "    print(f\"âœ… FAISS index initialized with {index.ntotal} vectors in {init_time:.4f}s\")\n",
    "\n",
    "    # Mapping: FAISS internal ID â†’ context_id\n",
    "    index_to_chunk = df_chunks.iloc[:init_size][\"context_id\"].tolist()\n",
    "\n",
    "    results = []\n",
    "\n",
    "    # --- Step 2: Batch updates ---\n",
    "    for batch_idx in tqdm(range(1, n_batches + 1)):\n",
    "        start_idx = (batch_idx - 1) * batch_size\n",
    "        end_idx = min(batch_idx * batch_size, remaining_size)\n",
    "        seen_end_idx = init_size + end_idx\n",
    "\n",
    "        # Get new batch of embeddings\n",
    "        batch_embeddings = chunk_embeddings[init_size + start_idx:init_size + end_idx].astype(np.float32)\n",
    "        batch_df_chunks = df_chunks.iloc[init_size + start_idx:init_size + end_idx]\n",
    "\n",
    "        # --- Add new data to FAISS ---\n",
    "        add_start = time.time()\n",
    "        index.add(batch_embeddings)\n",
    "        add_end = time.time()\n",
    "        add_time = add_end - add_start\n",
    "\n",
    "        # Extend mapping\n",
    "        index_to_chunk.extend(batch_df_chunks[\"context_id\"].tolist())\n",
    "\n",
    "        # --- Determine which queries to include ---\n",
    "        progress = batch_idx / n_batches\n",
    "        queries_in_seen = df_queries[df_queries[\"context_id\"].isin(index_to_chunk)]\n",
    "        queries_not_in_seen = df_queries[df_queries[\"context_id\"].isin(missing_context_ids)]\n",
    "        n_to_sample = int(len(queries_not_in_seen) * progress)\n",
    "        queries_sampled = (\n",
    "            queries_not_in_seen.sample(n=n_to_sample, random_state=42)\n",
    "            if n_to_sample > 0 else pd.DataFrame(columns=df_queries.columns)\n",
    "        )\n",
    "        df_queries_seen = pd.concat([queries_in_seen, queries_sampled]).reset_index(drop=True)\n",
    "\n",
    "        # --- Retrieval evaluation ---\n",
    "        retrieval_start = time.time()\n",
    "        metrics = evaluate_top_k_accuracy_faiss(\n",
    "            df_queries=df_queries_seen,\n",
    "            df_chunks=df_chunks,\n",
    "            faiss_index=index,\n",
    "            top_k_chunks=top_k_total\n",
    "        )\n",
    "        retrieval_end = time.time()\n",
    "        retrieval_time = retrieval_end - retrieval_start\n",
    "\n",
    "        # --- Store results ---\n",
    "        results.append({\n",
    "            \"batch\": batch_idx,\n",
    "            \"init_time\": init_time if batch_idx == 1 else 0,\n",
    "            \"add_time\": add_time,\n",
    "            \"retrieval_time\": retrieval_time,\n",
    "            \"metrics\": metrics,\n",
    "            \"total_vectors\": index.ntotal\n",
    "        })\n",
    "\n",
    "        # Save intermediate results\n",
    "        results_df = pd.DataFrame(results)\n",
    "        results_df.to_excel(\"../data/results/onlinekmeans_with_faiss_v4.xlsx\")\n",
    "\n",
    "    return pd.DataFrame(results)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Workflow"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_train = pd.read_excel(\"../data/labelled/squad_train_v2_semantic_chunking_clustered.xlsx\")\n",
    "df_queries_train = pd.read_excel(\"../data/prepared/squad_train_v2_queries.xlsx\")\n",
    "\n",
    "X_train = np.load(\"../data/tensors/squad_train_v4_semantic_chunking_l2.npy\")\n",
    "\n",
    "labels_train = df_train[\"cluster\"].values"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(84007, 10)"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_train.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(87599, 4)"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_queries_train.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'How much did Beyonce initially contribute to the foundation?'"
      ]
     },
     "execution_count": 23,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_queries_train.loc[1000, \"question\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [],
   "source": [
    "query = df_queries_train.loc[1000, \"question\"]\n",
    "query_emb = model.encode([query])[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Runtime: 0.00597 seconds\n",
      "Cluster-based retrieval:\n",
      "['Rolling Stone reported that the music industry was urging them to return the money they earned for the concerts; a spokesperson for BeyoncÃ© later confirmed to The Huffington Post that she donated the money to the Clinton Bush Haiti Fund.', 'After Hurricane Katrina in 2005, BeyoncÃ© and Rowland founded the Survivor Foundation to provide transitional housing for victims in the Houston area, to which BeyoncÃ© contributed an initial $250,000.', 'BeyoncÃ© would later speak of her mother as the person who helped her fight it.']\n"
     ]
    }
   ],
   "source": [
    "centroid_matrix, centroid_ids = compute_cluster_centroids(X_train, labels_train)\n",
    "\n",
    "start_time = time.time()\n",
    "\n",
    "top_chunks_cluster = retrieve_top_chunks_by_cluster(\n",
    "    query_embedding=query_emb,\n",
    "    chunk_embeddings=X_train,\n",
    "    df_chunks=df_train,\n",
    "    cluster_labels=labels_train,\n",
    "    top_n_clusters=1,\n",
    "    top_k_total=3,\n",
    "    centroid_matrix=centroid_matrix,\n",
    "    centroid_ids=centroid_ids\n",
    ")\n",
    "\n",
    "end_time = time.time()\n",
    "elapsed_time = end_time - start_time\n",
    "print(f\"Runtime: {elapsed_time:.5f} seconds\")\n",
    "print(\"Cluster-based retrieval:\")\n",
    "print(top_chunks_cluster['chunk_embed_text'].tolist())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Runtime: 0.26332 seconds\n",
      "Full retrieval:\n",
      "['Rolling Stone reported that the music industry was urging them to return the money they earned for the concerts; a spokesperson for BeyoncÃ© later confirmed to The Huffington Post that she donated the money to the Clinton Bush Haiti Fund.', 'After Hurricane Katrina in 2005, BeyoncÃ© and Rowland founded the Survivor Foundation to provide transitional housing for victims in the Houston area, to which BeyoncÃ© contributed an initial $250,000.', 'See: List of wealthiest foundations.']\n"
     ]
    }
   ],
   "source": [
    "start_time = time.time()\n",
    "\n",
    "top_chunks_full = retrieve_top_chunks_full(\n",
    "    query_embedding=query_emb,\n",
    "    chunk_embeddings=X_train,\n",
    "    df_chunks=df_train,\n",
    "    top_k_chunks=3\n",
    ")\n",
    "\n",
    "end_time = time.time()\n",
    "elapsed_time = end_time - start_time\n",
    "print(f\"Runtime: {elapsed_time:.5f} seconds\")\n",
    "print(\"Full retrieval:\")\n",
    "print(top_chunks_full['chunk_embed_text'].tolist())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Evaluation for retrival with cluster centroids vs full"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 79,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load data\n",
    "\n",
    "# FULL Ã©s CENTROID ezzel jÃ³!!!!!!!!\n",
    "\n",
    "X_semantic_train = np.load(\"../data/tensors/squad_train_v4_semantic_chunking_l2_missing.npy\")\n",
    "df_semantic_train = pd.read_excel(\"../data/labelled/squad_train_v4_semantic_chunking_clustered_missing.xlsx\")\n",
    "df_queries_train = pd.read_excel(\"../data/prepared/squad_train_v4_queries_missing.xlsx\")\n",
    "index = faiss.read_index(\"../data/faiss/squad_train_v4_semantic_chunking_l2_faiss_hnsw2.index\")\n",
    "\n",
    "labels_train = df_semantic_train[\"cluster\"].values"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "# FAISS ezzel lesz jÃ³!!!!\n",
    "\n",
    "import faiss\n",
    "index = faiss.read_index(\"../data/faiss/squad_train_v2_semantic_chunking_l2_faiss_hnsw2.index\")\n",
    "df_semantic_train = pd.read_excel(\"../data/labelled/squad_train_v2_semantic_chunking_clustered_missing.xlsx\")\n",
    "df_queries_train = pd.read_excel(\"../data/prepared/squad_train_v2_queries_missing.xlsx\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 80,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "500"
      ]
     },
     "execution_count": 80,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_semantic_train['cluster'].nunique()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 81,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "np.int64(13134)"
      ]
     },
     "execution_count": 81,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_queries_train['answer_start'].isna().sum()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# X_semantic_train = X_semantic_train[:4000]\n",
    "# df_semantic_train = df_semantic_train.iloc[:4000]\n",
    "\n",
    "# df_queries_train = df_queries_train[df_queries_train[\"context_id\"].isin(df_semantic_train[\"context_id\"].unique())].reset_index(drop=True)\n",
    "\n",
    "# labels_train = df_semantic_train[\"cluster\"].values"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 82,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Evaluating: Top-3 chunks in Top-5 clusters\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 2000/2000 [07:25<00:00,  4.49it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Evaluating: Top-3 chunks in Top-10 clusters\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 2000/2000 [07:46<00:00,  4.29it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Evaluating: Top-3 chunks in Top-20 clusters\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 2000/2000 [08:01<00:00,  4.15it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Evaluating: Top-3 chunks in Top-35 clusters\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 2000/2000 [08:27<00:00,  3.94it/s]\n",
      "100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 2000/2000 [14:40<00:00,  2.27it/s]\n",
      "100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 2000/2000 [07:23<00:00,  4.51it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Evaluating: Top-5 chunks in Top-5 clusters\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 2000/2000 [07:47<00:00,  4.28it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Evaluating: Top-5 chunks in Top-10 clusters\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 2000/2000 [08:09<00:00,  4.09it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Evaluating: Top-5 chunks in Top-20 clusters\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 2000/2000 [08:22<00:00,  3.98it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Evaluating: Top-5 chunks in Top-35 clusters\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 2000/2000 [08:36<00:00,  3.87it/s]\n",
      "100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 2000/2000 [14:35<00:00,  2.28it/s]\n",
      "100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 2000/2000 [07:56<00:00,  4.19it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Evaluating: Top-12 chunks in Top-5 clusters\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 2000/2000 [07:54<00:00,  4.21it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Evaluating: Top-12 chunks in Top-10 clusters\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 2000/2000 [07:57<00:00,  4.19it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Evaluating: Top-12 chunks in Top-20 clusters\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 2000/2000 [08:15<00:00,  4.03it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Evaluating: Top-12 chunks in Top-35 clusters\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 2000/2000 [08:57<00:00,  3.72it/s]\n",
      "100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 2000/2000 [15:20<00:00,  2.17it/s]\n",
      "100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 2000/2000 [07:32<00:00,  4.42it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Evaluating: Top-25 chunks in Top-5 clusters\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 2000/2000 [07:58<00:00,  4.18it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Evaluating: Top-25 chunks in Top-10 clusters\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 2000/2000 [08:07<00:00,  4.11it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Evaluating: Top-25 chunks in Top-20 clusters\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 2000/2000 [08:29<00:00,  3.93it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Evaluating: Top-25 chunks in Top-35 clusters\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 2000/2000 [08:53<00:00,  3.75it/s]\n",
      "100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 2000/2000 [14:52<00:00,  2.24it/s]\n",
      "100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 2000/2000 [07:30<00:00,  4.44it/s]\n"
     ]
    }
   ],
   "source": [
    "# Benchmark\n",
    "#3,5,12,25\n",
    "top_ks = [3, 5, 12, 25]\n",
    "top_n_clusters = [5, 10, 20, 35]\n",
    "\n",
    "results_centroid = []\n",
    "results_full = []\n",
    "results_faiss = []\n",
    "for top_k in top_ks:\n",
    "    for top_n_cluster in top_n_clusters:\n",
    "        print(f\"Evaluating: Top-{top_k} chunks in Top-{top_n_cluster} clusters\")\n",
    "        \n",
    "        start_centroid = time.time()\n",
    "        centroid_metrics = evaluate_top_k_accuracy(df_queries_train, X_semantic_train, df_semantic_train, labels_train, top_n_clusters=top_n_cluster, top_k_total=top_k)\n",
    "        end_centroid = time.time()\n",
    "        \n",
    "        results_centroid.append({\n",
    "            \"top_k\": top_k,\n",
    "            \"top_n_clusters\": top_n_cluster,\n",
    "            \"centroid_metrics\": centroid_metrics,\n",
    "            \"centroid_time\": end_centroid - start_centroid\n",
    "        })\n",
    "        \n",
    "        results_df_centroid = pd.DataFrame(results_centroid)\n",
    "        results_df_centroid.to_excel(\"../data/results/hyperparameter_tuning_centroid_vs_full/centroid_results_kmeans500_v4_l2_final.xlsx\")\n",
    "        \n",
    "    start_full = time.time()\n",
    "    full_metrics = evaluate_top_k_accuracy_full(df_queries_train, X_semantic_train, df_semantic_train, top_k_chunks=top_k)\n",
    "    end_full = time.time()\n",
    "    results_full.append({\n",
    "        \"top_k\": top_k,\n",
    "        \"full_metrics\": full_metrics,\n",
    "        \"full_time\": end_full - start_full\n",
    "    })\n",
    "    results_df_full = pd.DataFrame(results_full)\n",
    "    results_df_full.to_excel(\"../data/results/hyperparameter_tuning_centroid_vs_full/full_results_kmeans500_v4_l2_final.xlsx\")\n",
    "    \n",
    "    \n",
    "    \n",
    "    start_faiss = time.time()\n",
    "    faiss_metrics = evaluate_top_k_accuracy_faiss(df_queries_train, index, df_semantic_train, top_k_chunks=top_k)\n",
    "    end_faiss = time.time()\n",
    "    results_faiss.append({\n",
    "        \"top_k\": top_k,\n",
    "        \"faiss_metrics\": faiss_metrics,\n",
    "        \"faiss_time\": end_faiss - start_faiss\n",
    "    })\n",
    "    results_df_faiss = pd.DataFrame(results_faiss)\n",
    "    results_df_faiss.to_excel(\"../data/results/hyperparameter_tuning_centroid_vs_full/faiss_results_kmeans500_v4_l2_final_hnsw.xlsx\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "1.0"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(np.unique(labels_train)) / 500"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 87599/87599 [3:28:17<00:00,  7.01it/s]   \n"
     ]
    }
   ],
   "source": [
    "start_full = time.time()\n",
    "full_metrics = evaluate_top_k_accuracy_full(df_queries_train, X_semantic_train, df_semantic_train, top_k_chunks=25)\n",
    "end_full = time.time()\n",
    "results_full.append({\n",
    "    \"top_k\": 25,\n",
    "    \"full_metrics\": full_metrics,\n",
    "    \"full_time\": end_full - start_full\n",
    "})\n",
    "results_df_full = pd.DataFrame(results_full)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>top_k</th>\n",
       "      <th>full_metrics</th>\n",
       "      <th>full_time</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>3</td>\n",
       "      <td>{'doc_accuracy': 0.8036735579173279, 'chunk_ac...</td>\n",
       "      <td>10972.379970</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>5</td>\n",
       "      <td>{'doc_accuracy': 0.8522357561159374, 'chunk_ac...</td>\n",
       "      <td>10506.523075</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>12</td>\n",
       "      <td>{'doc_accuracy': 0.9135035788079773, 'chunk_ac...</td>\n",
       "      <td>11872.974770</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>25</td>\n",
       "      <td>{'doc_accuracy': 0.9460039498167787, 'chunk_ac...</td>\n",
       "      <td>12497.922858</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   top_k                                       full_metrics     full_time\n",
       "0      3  {'doc_accuracy': 0.8036735579173279, 'chunk_ac...  10972.379970\n",
       "1      5  {'doc_accuracy': 0.8522357561159374, 'chunk_ac...  10506.523075\n",
       "2     12  {'doc_accuracy': 0.9135035788079773, 'chunk_ac...  11872.974770\n",
       "3     25  {'doc_accuracy': 0.9460039498167787, 'chunk_ac...  12497.922858"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "results_df_full"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "results_df_full.to_excel(\"../data/results/hyperparameter_tuning_centroid_vs_full/full_results.xlsx\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Evaluate retrieval with MiniBatchKMeans"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load data\n",
    "X_semantic_train = np.load(\"../data/tensors/squad_train_v4_semantic_chunking_l2_missing.npy\")\n",
    "df_semantic_train = pd.read_excel(\"../data/prepared/squad_train_v4_semantic_chunking_missing.xlsx\")\n",
    "df_queries_train = pd.read_excel(\"../data/prepared/squad_train_v4_queries_missing.xlsx\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ðŸ”§ Using 50% of data (35713 samples) for initialization\n",
      "âœ… Initialization done in 17.0099 s\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 2000/2000 [08:06<00:00,  4.11it/s]\n",
      "100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 2000/2000 [07:40<00:00,  4.34it/s]\n",
      "100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 2000/2000 [07:49<00:00,  4.26it/s]\n",
      "100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 2000/2000 [07:48<00:00,  4.27it/s]\n",
      "100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 2000/2000 [07:50<00:00,  4.25it/s]\n",
      "100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 2000/2000 [07:47<00:00,  4.28it/s]\n",
      "100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 2000/2000 [07:46<00:00,  4.29it/s]\n",
      "100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 2000/2000 [07:45<00:00,  4.29it/s]\n",
      "100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 2000/2000 [07:52<00:00,  4.24it/s]\n",
      "100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 2000/2000 [07:48<00:00,  4.27it/s]\n",
      "100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 2000/2000 [07:52<00:00,  4.24it/s]]\n",
      "100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 2000/2000 [07:59<00:00,  4.17it/s] \n",
      "100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 2000/2000 [07:53<00:00,  4.22it/s]\n",
      "100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 2000/2000 [07:57<00:00,  4.19it/s]\n",
      "100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 2000/2000 [07:54<00:00,  4.21it/s]\n",
      "100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 2000/2000 [07:59<00:00,  4.17it/s]\n",
      "100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 2000/2000 [07:57<00:00,  4.19it/s]\n",
      "100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 2000/2000 [07:56<00:00,  4.20it/s]\n",
      "100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 18/18 [2:21:58<00:00, 473.27s/it]\n"
     ]
    }
   ],
   "source": [
    "# --- FuttatÃ¡s ---\n",
    "results_df = minibatchkmeans_retrieval_evaluation(\n",
    "    chunk_embeddings=X_semantic_train,\n",
    "    df_chunks=df_semantic_train,\n",
    "    df_queries=df_queries_train,\n",
    "    n_clusters=500,\n",
    "    batch_size=2000,\n",
    "    top_k_total=10,\n",
    "    init_fraction=0.5, # 0.07 -> 5000 sample\n",
    "    top_n_clusters=10\n",
    ")\n",
    "results_df.to_excel(\"../data/results/onlinekmeans_with_minibatchkmeans_v4_final_smallinitsize.xlsx\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 111,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load data\n",
    "X_semantic_train = np.load(\"../data/tensors/squad_train_v2_semantic_chunking_l2_missing.npy\")\n",
    "df_semantic_train = pd.read_excel(\"../data/prepared/squad_train_v2_semantic_chunking_missing.xlsx\")\n",
    "df_queries_train = pd.read_excel(\"../data/prepared/squad_train_v2_queries_missing.xlsx\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 120,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ðŸ”§ Using 50% of data (35713 samples) for initialization\n",
      "âš™ï¸ Converting embeddings to River-friendly dict format...\n",
      "âœ… Conversion done.\n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[31m---------------------------------------------------------------------------\u001b[39m",
      "\u001b[31mKeyboardInterrupt\u001b[39m                         Traceback (most recent call last)",
      "\u001b[36mCell\u001b[39m\u001b[36m \u001b[39m\u001b[32mIn[120]\u001b[39m\u001b[32m, line 1\u001b[39m\n\u001b[32m----> \u001b[39m\u001b[32m1\u001b[39m results_df = \u001b[43mriver_retrieval_evaluation\u001b[49m\u001b[43m(\u001b[49m\n\u001b[32m      2\u001b[39m \u001b[43m    \u001b[49m\u001b[43mchunk_embeddings\u001b[49m\u001b[43m=\u001b[49m\u001b[43mX_semantic_train\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m      3\u001b[39m \u001b[43m    \u001b[49m\u001b[43mdf_chunks\u001b[49m\u001b[43m=\u001b[49m\u001b[43mdf_semantic_train\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m      4\u001b[39m \u001b[43m    \u001b[49m\u001b[43mdf_queries\u001b[49m\u001b[43m=\u001b[49m\u001b[43mdf_queries_train\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m      5\u001b[39m \u001b[43m    \u001b[49m\u001b[43mn_clusters\u001b[49m\u001b[43m=\u001b[49m\u001b[32;43m500\u001b[39;49m\u001b[43m,\u001b[49m\n\u001b[32m      6\u001b[39m \u001b[43m    \u001b[49m\u001b[43mbatch_size\u001b[49m\u001b[43m=\u001b[49m\u001b[32;43m2000\u001b[39;49m\u001b[43m,\u001b[49m\n\u001b[32m      7\u001b[39m \u001b[43m    \u001b[49m\u001b[43mtop_k_total\u001b[49m\u001b[43m=\u001b[49m\u001b[32;43m10\u001b[39;49m\u001b[43m,\u001b[49m\n\u001b[32m      8\u001b[39m \u001b[43m    \u001b[49m\u001b[43minit_fraction\u001b[49m\u001b[43m=\u001b[49m\u001b[32;43m0.5\u001b[39;49m\u001b[43m,\u001b[49m\n\u001b[32m      9\u001b[39m \u001b[43m    \u001b[49m\u001b[43mtop_n_clusters\u001b[49m\u001b[43m=\u001b[49m\u001b[32;43m10\u001b[39;49m\n\u001b[32m     10\u001b[39m \u001b[43m)\u001b[49m\n\u001b[32m     12\u001b[39m results_df.to_excel(\u001b[33m\"\u001b[39m\u001b[33m../data/results/onlinekmeans_with_river_v2_final.xlsx\u001b[39m\u001b[33m\"\u001b[39m)\n",
      "\u001b[36mCell\u001b[39m\u001b[36m \u001b[39m\u001b[32mIn[119]\u001b[39m\u001b[32m, line 37\u001b[39m, in \u001b[36mriver_retrieval_evaluation\u001b[39m\u001b[34m(chunk_embeddings, df_chunks, df_queries, n_clusters, batch_size, top_k_total, init_fraction, top_n_clusters)\u001b[39m\n\u001b[32m     35\u001b[39m init_start = time.time()\n\u001b[32m     36\u001b[39m \u001b[38;5;28;01mfor\u001b[39;00m emb_dict \u001b[38;5;129;01min\u001b[39;00m emb_dicts[:init_size]:\n\u001b[32m---> \u001b[39m\u001b[32m37\u001b[39m     \u001b[43mstream_clusterer\u001b[49m\u001b[43m.\u001b[49m\u001b[43mlearn_one\u001b[49m\u001b[43m(\u001b[49m\u001b[43memb_dict\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m     38\u001b[39m init_end = time.time()\n\u001b[32m     39\u001b[39m init_time = init_end - init_start\n",
      "\u001b[36mFile \u001b[39m\u001b[32mc:\\Users\\CZB3BP\\.conda\\envs\\szakdoga\\Lib\\site-packages\\river\\cluster\\k_means.py:120\u001b[39m, in \u001b[36mKMeans.learn_one\u001b[39m\u001b[34m(self, x)\u001b[39m\n\u001b[32m    119\u001b[39m \u001b[38;5;28;01mdef\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34mlearn_one\u001b[39m(\u001b[38;5;28mself\u001b[39m, x):\n\u001b[32m--> \u001b[39m\u001b[32m120\u001b[39m     \u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43mlearn_predict_one\u001b[49m\u001b[43m(\u001b[49m\u001b[43mx\u001b[49m\u001b[43m)\u001b[49m\n",
      "\u001b[36mFile \u001b[39m\u001b[32mc:\\Users\\CZB3BP\\.conda\\envs\\szakdoga\\Lib\\site-packages\\river\\cluster\\k_means.py:111\u001b[39m, in \u001b[36mKMeans.learn_predict_one\u001b[39m\u001b[34m(self, x)\u001b[39m\n\u001b[32m    108\u001b[39m \u001b[38;5;250m\u001b[39m\u001b[33;03m\"\"\"Equivalent to `k_means.learn_one(x).predict_one(x)`, but faster.\"\"\"\u001b[39;00m\n\u001b[32m    110\u001b[39m \u001b[38;5;66;03m# Find the cluster with the closest center\u001b[39;00m\n\u001b[32m--> \u001b[39m\u001b[32m111\u001b[39m closest = \u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43mpredict_one\u001b[49m\u001b[43m(\u001b[49m\u001b[43mx\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m    113\u001b[39m \u001b[38;5;66;03m# Move the cluster's center\u001b[39;00m\n\u001b[32m    114\u001b[39m \u001b[38;5;28;01mfor\u001b[39;00m i, xi \u001b[38;5;129;01min\u001b[39;00m x.items():\n",
      "\u001b[36mFile \u001b[39m\u001b[32mc:\\Users\\CZB3BP\\.conda\\envs\\szakdoga\\Lib\\site-packages\\river\\cluster\\k_means.py:129\u001b[39m, in \u001b[36mKMeans.predict_one\u001b[39m\u001b[34m(self, x)\u001b[39m\n\u001b[32m    124\u001b[39m     center = \u001b[38;5;28mself\u001b[39m.centers[c]\n\u001b[32m    125\u001b[39m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28msum\u001b[39m(\n\u001b[32m    126\u001b[39m         (\u001b[38;5;28mabs\u001b[39m(center[k] - x.get(k, \u001b[32m0\u001b[39m))) ** \u001b[38;5;28mself\u001b[39m.p \u001b[38;5;28;01mfor\u001b[39;00m k \u001b[38;5;129;01min\u001b[39;00m {*center.keys(), *x.keys()}\n\u001b[32m    127\u001b[39m     )\n\u001b[32m--> \u001b[39m\u001b[32m129\u001b[39m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mmin\u001b[39;49m\u001b[43m(\u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43mcenters\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mkey\u001b[49m\u001b[43m=\u001b[49m\u001b[43mget_distance\u001b[49m\u001b[43m)\u001b[49m\n",
      "\u001b[36mFile \u001b[39m\u001b[32mc:\\Users\\CZB3BP\\.conda\\envs\\szakdoga\\Lib\\site-packages\\river\\cluster\\k_means.py:125\u001b[39m, in \u001b[36mKMeans.predict_one.<locals>.get_distance\u001b[39m\u001b[34m(c)\u001b[39m\n\u001b[32m    123\u001b[39m \u001b[38;5;28;01mdef\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34mget_distance\u001b[39m(c):\n\u001b[32m    124\u001b[39m     center = \u001b[38;5;28mself\u001b[39m.centers[c]\n\u001b[32m--> \u001b[39m\u001b[32m125\u001b[39m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43msum\u001b[39;49m\u001b[43m(\u001b[49m\n\u001b[32m    126\u001b[39m \u001b[43m        \u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;28;43mabs\u001b[39;49m\u001b[43m(\u001b[49m\u001b[43mcenter\u001b[49m\u001b[43m[\u001b[49m\u001b[43mk\u001b[49m\u001b[43m]\u001b[49m\u001b[43m \u001b[49m\u001b[43m-\u001b[49m\u001b[43m \u001b[49m\u001b[43mx\u001b[49m\u001b[43m.\u001b[49m\u001b[43mget\u001b[49m\u001b[43m(\u001b[49m\u001b[43mk\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[32;43m0\u001b[39;49m\u001b[43m)\u001b[49m\u001b[43m)\u001b[49m\u001b[43m)\u001b[49m\u001b[43m \u001b[49m\u001b[43m*\u001b[49m\u001b[43m*\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43mp\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43;01mfor\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[43mk\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;129;43;01min\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[43m{\u001b[49m\u001b[43m*\u001b[49m\u001b[43mcenter\u001b[49m\u001b[43m.\u001b[49m\u001b[43mkeys\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43m*\u001b[49m\u001b[43mx\u001b[49m\u001b[43m.\u001b[49m\u001b[43mkeys\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\u001b[43m}\u001b[49m\n\u001b[32m    127\u001b[39m \u001b[43m    \u001b[49m\u001b[43m)\u001b[49m\n",
      "\u001b[36mFile \u001b[39m\u001b[32mc:\\Users\\CZB3BP\\.conda\\envs\\szakdoga\\Lib\\site-packages\\river\\cluster\\k_means.py:126\u001b[39m, in \u001b[36m<genexpr>\u001b[39m\u001b[34m(.0)\u001b[39m\n\u001b[32m    123\u001b[39m \u001b[38;5;28;01mdef\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34mget_distance\u001b[39m(c):\n\u001b[32m    124\u001b[39m     center = \u001b[38;5;28mself\u001b[39m.centers[c]\n\u001b[32m    125\u001b[39m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28msum\u001b[39m(\n\u001b[32m--> \u001b[39m\u001b[32m126\u001b[39m         (\u001b[38;5;28;43mabs\u001b[39;49m\u001b[43m(\u001b[49m\u001b[43mcenter\u001b[49m\u001b[43m[\u001b[49m\u001b[43mk\u001b[49m\u001b[43m]\u001b[49m\u001b[43m \u001b[49m\u001b[43m-\u001b[49m\u001b[43m \u001b[49m\u001b[43mx\u001b[49m\u001b[43m.\u001b[49m\u001b[43mget\u001b[49m\u001b[43m(\u001b[49m\u001b[43mk\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[32;43m0\u001b[39;49m\u001b[43m)\u001b[49m\u001b[43m)\u001b[49m) ** \u001b[38;5;28mself\u001b[39m.p \u001b[38;5;28;01mfor\u001b[39;00m k \u001b[38;5;129;01min\u001b[39;00m {*center.keys(), *x.keys()}\n\u001b[32m    127\u001b[39m     )\n",
      "\u001b[31mKeyboardInterrupt\u001b[39m: "
     ]
    }
   ],
   "source": [
    "results_df = river_retrieval_evaluation(\n",
    "    chunk_embeddings=X_semantic_train,\n",
    "    df_chunks=df_semantic_train,\n",
    "    df_queries=df_queries_train,\n",
    "    n_clusters=500,\n",
    "    batch_size=2000,\n",
    "    top_k_total=10,\n",
    "    init_fraction=0.5,\n",
    "    top_n_clusters=10\n",
    ")\n",
    "\n",
    "results_df.to_excel(\"../data/results/onlinekmeans_with_river_v2_final.xlsx\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Evaluate retrieval with online clustering"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load data\n",
    "X_semantic_train = np.load(\"../data/tensors/squad_train_v4_semantic_chunking_l2_missing.npy\")\n",
    "df_semantic_train = pd.read_excel(\"../data/prepared/squad_train_v4_semantic_chunking_missing.xlsx\")\n",
    "df_queries_train = pd.read_excel(\"../data/prepared/squad_train_v4_queries_missing.xlsx\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ðŸ”§ Using 50% of data (35713 samples) for initialization\n",
      "âœ… Initialization done in 106.6367 s\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 2000/2000 [07:35<00:00,  4.39it/s]\n",
      "100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 2000/2000 [07:55<00:00,  4.21it/s]\n",
      "100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 2000/2000 [07:56<00:00,  4.19it/s]\n",
      "100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 2000/2000 [07:47<00:00,  4.28it/s]\n",
      "100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 2000/2000 [07:49<00:00,  4.26it/s]\n",
      "100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 2000/2000 [07:51<00:00,  4.24it/s]\n",
      "100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 2000/2000 [07:56<00:00,  4.20it/s]\n",
      "100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 2000/2000 [08:01<00:00,  4.16it/s]\n",
      "100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 2000/2000 [08:09<00:00,  4.08it/s]\n",
      "100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 2000/2000 [07:50<00:00,  4.25it/s]\n",
      "100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 2000/2000 [07:57<00:00,  4.19it/s]]\n",
      "100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 2000/2000 [08:07<00:00,  4.10it/s]]\n",
      "100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 2000/2000 [07:54<00:00,  4.21it/s]]\n",
      "100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 2000/2000 [07:56<00:00,  4.20it/s] \n",
      "100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 2000/2000 [07:58<00:00,  4.18it/s]\n",
      "100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 2000/2000 [07:58<00:00,  4.18it/s]\n",
      "100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 2000/2000 [07:57<00:00,  4.19it/s]\n",
      "100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 2000/2000 [07:55<00:00,  4.21it/s]\n",
      "100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 18/18 [2:59:40<00:00, 598.93s/it]\n"
     ]
    }
   ],
   "source": [
    "results_df = kmeans_retrieval_evaluation(\n",
    "    chunk_embeddings=X_semantic_train,\n",
    "    df_chunks=df_semantic_train,\n",
    "    df_queries=df_queries_train,\n",
    "    n_clusters=500,\n",
    "    batch_size=2000,\n",
    "    top_k_total=10,\n",
    "    init_fraction=0.5,\n",
    "    top_n_clusters=10)\n",
    "\n",
    "results_df.to_excel(\"../data/results/onlinekmeans_with_kmeans_v4_final.xlsx\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(18891, 16058)"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_queries_train['context_id'].nunique(), df_semantic_train['context_id'].nunique()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ðŸ”§ Using 50% of data (35713 samples) for initialization\n",
      "âœ… Initialization done in 77.9709 s\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 2000/2000 [07:40<00:00,  4.35it/s]\n",
      "100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 2000/2000 [07:48<00:00,  4.27it/s]\n",
      "100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 2000/2000 [07:50<00:00,  4.25it/s]\n",
      "100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 2000/2000 [07:49<00:00,  4.26it/s]\n",
      "100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 2000/2000 [07:46<00:00,  4.29it/s]\n",
      "100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 2000/2000 [07:45<00:00,  4.30it/s]\n",
      "100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 2000/2000 [07:54<00:00,  4.22it/s]\n",
      "100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 2000/2000 [07:50<00:00,  4.25it/s]\n",
      "100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 2000/2000 [07:50<00:00,  4.25it/s]\n",
      "100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 2000/2000 [07:46<00:00,  4.28it/s]\n",
      "100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 2000/2000 [07:55<00:00,  4.20it/s]]\n",
      "100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 2000/2000 [07:54<00:00,  4.21it/s] \n",
      "100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 2000/2000 [07:51<00:00,  4.24it/s]\n",
      "100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 2000/2000 [07:48<00:00,  4.27it/s]\n",
      "100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 2000/2000 [07:46<00:00,  4.29it/s]\n",
      "100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 2000/2000 [07:47<00:00,  4.28it/s]\n",
      "100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 2000/2000 [07:45<00:00,  4.29it/s]\n",
      "100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 2000/2000 [07:43<00:00,  4.31it/s]\n",
      "100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 18/18 [2:21:04<00:00, 470.27s/it]\n"
     ]
    }
   ],
   "source": [
    "results_df = online_kmeans_retrieval_evaluation(\n",
    "    chunk_embeddings=X_semantic_train,\n",
    "    df_chunks=df_semantic_train,\n",
    "    df_queries=df_queries_train,\n",
    "    n_clusters=360,\n",
    "    max_clusters=2000,\n",
    "    batch_size=2000,\n",
    "    top_k_total=10,\n",
    "    metric=\"cosine\",\n",
    "    init_fraction=0.5,\n",
    "    merge_threshold=0.08,    \n",
    "    decay=1.0,\n",
    "    new_cluster_threshold=0.8,\n",
    "    top_n_clusters=10\n",
    ")\n",
    "\n",
    "results_df.to_excel(\"../data/results/onlinekmeans_v4_from360clusters_final.xlsx\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Evaluate online FAISS"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load data\n",
    "X_semantic_train = np.load(\"../data/tensors/squad_train_v4_semantic_chunking_l2_missing.npy\")\n",
    "df_semantic_train = pd.read_excel(\"../data/prepared/squad_train_v4_semantic_chunking_missing.xlsx\")\n",
    "df_queries_train = pd.read_excel(\"../data/prepared/squad_train_v4_queries_missing.xlsx\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ðŸ”§ Using 50% of data (35713 samples) for FAISS initialization\n",
      "âœ… FAISS index initialized with 35713 vectors in 10.3373s\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 2000/2000 [07:14<00:00,  4.60it/s]\n",
      "100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 2000/2000 [07:21<00:00,  4.53it/s]\n",
      "100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 2000/2000 [07:15<00:00,  4.59it/s]\n",
      "100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 2000/2000 [07:08<00:00,  4.66it/s]\n",
      "100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 2000/2000 [07:15<00:00,  4.59it/s]\n",
      "100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 2000/2000 [07:04<00:00,  4.71it/s]\n",
      "100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 2000/2000 [07:08<00:00,  4.67it/s]\n",
      "100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 2000/2000 [07:10<00:00,  4.64it/s]\n",
      "100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 2000/2000 [07:15<00:00,  4.60it/s]\n",
      "100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 2000/2000 [07:06<00:00,  4.69it/s]\n",
      "100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 2000/2000 [07:08<00:00,  4.67it/s]\n",
      "100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 2000/2000 [07:12<00:00,  4.63it/s]\n",
      "100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 2000/2000 [07:09<00:00,  4.66it/s]\n",
      "100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 2000/2000 [07:11<00:00,  4.63it/s]\n",
      "100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 2000/2000 [07:04<00:00,  4.71it/s]\n",
      "100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 2000/2000 [07:05<00:00,  4.70it/s]\n",
      "100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 2000/2000 [07:07<00:00,  4.68it/s]\n",
      "100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 2000/2000 [07:04<00:00,  4.71it/s]\n",
      "100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 18/18 [2:09:23<00:00, 431.31s/it]\n"
     ]
    }
   ],
   "source": [
    "results_df = faiss_retrieval_evaluation(\n",
    "    chunk_embeddings=X_semantic_train,\n",
    "    df_chunks=df_semantic_train,\n",
    "    df_queries=df_queries_train,\n",
    "    batch_size=2000,\n",
    "    top_k_total=10,\n",
    "    init_fraction=0.5,\n",
    "    metric=\"cosine\"\n",
    ")\n",
    "\n",
    "results_df.to_excel(\"../data/results/onlinekmeans_with_faiss_v4_final.xlsx\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "szakdoga",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.11"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
